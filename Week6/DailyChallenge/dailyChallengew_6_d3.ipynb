{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNtiTrJ4gmu040SqbRhaKZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e54030ee06194660afa16290e9de4a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b34e692a9d403e80fdca3981a2379c",
              "IPY_MODEL_a2e2647844d94a58a56ff67b98dbce7b",
              "IPY_MODEL_2767e2bd8b034382866ab07a701315b2"
            ],
            "layout": "IPY_MODEL_8f0d18c3bc2b4b13999cd16b98128b0d"
          }
        },
        "e5b34e692a9d403e80fdca3981a2379c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e418f8beb9654e74ae724f27331db57b",
            "placeholder": "​",
            "style": "IPY_MODEL_805817e127ea4b2aa144e0bfb27d64c3",
            "value": "Map: 100%"
          }
        },
        "a2e2647844d94a58a56ff67b98dbce7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf9cfdb285b64ae99ccabb01ce213be9",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fc0a3a1494c48858c2cc59ed7135e49",
            "value": 4000
          }
        },
        "2767e2bd8b034382866ab07a701315b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981f1bf39fc74df6bdf9b69198848214",
            "placeholder": "​",
            "style": "IPY_MODEL_e64aeef743244591b066a5e6b5232713",
            "value": " 4000/4000 [00:01&lt;00:00, 3708.60 examples/s]"
          }
        },
        "8f0d18c3bc2b4b13999cd16b98128b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e418f8beb9654e74ae724f27331db57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805817e127ea4b2aa144e0bfb27d64c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9cfdb285b64ae99ccabb01ce213be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc0a3a1494c48858c2cc59ed7135e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "981f1bf39fc74df6bdf9b69198848214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64aeef743244591b066a5e6b5232713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386da149ca8049e6a871cf68ddeeb4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9527193f827f4929a7619ec73f759487",
              "IPY_MODEL_3ce63047cc004e3bb35ebc9816102b23",
              "IPY_MODEL_30585fafb71d4cb69c3195ef1310bdee"
            ],
            "layout": "IPY_MODEL_317e1d9633d440cca2a49d068323890c"
          }
        },
        "9527193f827f4929a7619ec73f759487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a481589d4484153a1b9710266b0aea4",
            "placeholder": "​",
            "style": "IPY_MODEL_3c97ebc959c44657b730b4ec6219a084",
            "value": "Map: 100%"
          }
        },
        "3ce63047cc004e3bb35ebc9816102b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1a7acb1b8846b583cd484766a0e386",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3026b91cc3cd49849327cae6223cd5e1",
            "value": 1000
          }
        },
        "30585fafb71d4cb69c3195ef1310bdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c970637b8263426f93aa0efb631be5e8",
            "placeholder": "​",
            "style": "IPY_MODEL_57f0ae01209542ab909ad7c3b6e4b055",
            "value": " 1000/1000 [00:00&lt;00:00, 3220.10 examples/s]"
          }
        },
        "317e1d9633d440cca2a49d068323890c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a481589d4484153a1b9710266b0aea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c97ebc959c44657b730b4ec6219a084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b1a7acb1b8846b583cd484766a0e386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3026b91cc3cd49849327cae6223cd5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c970637b8263426f93aa0efb631be5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f0ae01209542ab909ad7c3b6e4b055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoukrim/AI/blob/main/Week6/DailyChallenge/dailyChallengew_6_d3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @Author Adil MOUKRIM\n",
        "@ Daily Challenge: Fine-Tuning GPT-2 for SMS Spam Classification (Legacy transformers API)\n",
        "\n",
        "\n",
        "In this daily challenge, you’ll fine-tune a pre-trained GPT-2 model to classify SMS messages as spam or ham (not spam). We’ll work through loading the dataset, inspecting its schema, tokenizing examples, adapting to an older transformers version, and running training and evaluation with the classic do_train/do_eval flags.\n",
        "\n",
        "\n",
        "\n",
        "👩‍🏫 👩🏿‍🏫 What You’ll learn\n",
        "How to load and explore a custom text-classification dataset\n",
        "Inspecting and aligning column names for tokenization\n",
        "Tokenizing text for GPT-2 (with its peculiar padding setup)\n",
        "Initializing GPT2ForSequenceClassification\n",
        "Defining and computing multiple evaluation metrics\n",
        "Configuring TrainingArguments for transformers < 4.4 (using do_train, eval_steps, etc.)\n",
        "Running fine-tuning with Trainer and interpreting results\n",
        "Common pitfalls when using legacy APIs\n",
        "\n",
        "\n",
        "🛠️ What you will create\n",
        "By the end of this challenge, you will have built:\n",
        "\n",
        "A tokenized SMS dataset compatible with GPT-2’s requirements, including custom padding and truncation.\n",
        "A fine-tuned GPT2ForSequenceClassification model that can accurately label incoming SMS messages as spam or ham.\n",
        "A complete training pipeline using the legacy do_train/do_eval flags in TrainingArguments, with periodic checkpointing, logging, and evaluation.\n",
        "A set of evaluation metrics (accuracy, precision, recall, F1) computed at each validation step and summarized after training.\n",
        "A reusable Jupyter notebook that ties everything together—from dataset loading and inspection, through model initialization and tokenization, to training, evaluation, and results interpretation.\n",
        "\n",
        "\n",
        "💼 Prerequisites\n",
        "Python 3.7+\n",
        "Installed packages: datasets, evaluate, transformers>=4.0.0,<4.4.0\n",
        "Basic familiarity with Hugging Face’s datasets and transformers libraries\n",
        "GitHub or Colab access for executing the notebook\n",
        "A Hugging Face API and a WeightAndBiases API, for instructions on how to get it, click here.\n",
        "\n",
        "\n",
        "Task\n",
        "We will guide you through making a fine-tuning a GPT-2 model to classify SMS messages as spam or ham using an older version of transformers (<4.4). Follow the steps below and complete the “TODO” in the code.\n",
        "\n",
        "1. Setup : Install required packages datasets, evaluate and transformers[sentencepiece].\n",
        "\n",
        "%pip install --quiet datasets evaluate transformers[sentencepiece]\n",
        "\n",
        "\n",
        "2. Load & Inspect Dataset :\n",
        "\n",
        "from datasets import TODO #import load_dataset\n",
        "TODO # import pandas\n",
        "\n",
        "# Load the UCI SMS Spam dataset (sms_spam) from Hugging Face hub\n",
        "raw = TODO\n",
        "\n",
        "# We'll use 4,000 for train, 1,000 for validation\n",
        "train_ds = TODO\n",
        "val_ds   = TODO\n",
        "\n",
        "TODO  # print the features of the train dataset. It should show 'sms' and 'label'\n",
        "\n",
        "\n",
        "3. Tokenization :\n",
        "\n",
        "from transformers import TODO # import GPT2Tokenizer\n",
        "\n",
        "\n",
        "model_name = TODO #load the tokenize, we will use GPT2\n",
        "tokenizer  = TODO\n",
        "# GPT-2 has no pad token by default—set it to eos\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_fn(examples):\n",
        "    # returns input_ids, attention_mask; keep max_length small for SMS\n",
        "    return tokenizer(\n",
        "        examples[\"sms\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "train_tok = TODO #apply the tokenization by loading the subset using .map function\n",
        "val_tok   = TODO #apply the tokenization by loading the subset using .map function\n",
        "\n",
        "\n",
        "\n",
        "4. Model Initialization\n",
        "\n",
        "import torch\n",
        "TODO  #import GPT2ForSequenceClassification\n",
        "\n",
        "model = GPT2ForSequenceClassification.from_pretrained( # Load GPT-2 with sequence classification head\n",
        "    model_name,\n",
        "    num_labels=TODO,           # spam vs. ham\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "\n",
        "5. Metrics Definition\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy  = evaluate.load(\"accuracy\")\n",
        "precision = # apply the function used for accurracy but for precision\n",
        "recall    = # apply the function used for accurracy but for recall\n",
        "f1        = # apply the function used for accurracy but for F1\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision\": TODO, # apply the function used for accurracy but for precision\n",
        "        \"recall\":    TODO, # apply the function used for accurracy but for recall\n",
        "        \"f1\":        TODO # apply the function used for accurracy but for F1\n",
        "    }\n",
        "\n",
        "\n",
        "In an imbalanced dataset like SMS spam (often more “ham” than “spam”), why is it important to track precision and recall alongside accuracy?\n",
        "How would you interpret a model that achieves high accuracy but low recall on the spam class?\n",
        "\n",
        "\n",
        "6. TrainingArguments Configuration\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=TODO\n",
        "    do_train=True,                 # turn on training\n",
        "    do_eval=True,                  # turn on evaluation\n",
        "    eval_steps=TODO,                # run .evaluate() every 500 steps\n",
        "    save_steps=TODO,                # save a checkpoint every 500 steps\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=TODO,             # log metrics every 500 steps\n",
        "\n",
        "    per_device_train_batch_size=TODO,\n",
        "    per_device_eval_batch_size=TODO,\n",
        "    num_train_epochs=TODO,\n",
        "    learning_rate=TODO,\n",
        "    weight_decay=TODO,\n",
        "\n",
        "    report_to=None,                # disable integrations\n",
        "    save_total_limit=1,            # only keep last checkpoint\n",
        ")\n",
        "\n",
        "\n",
        "What effect does weight_decay have during fine-tuning? When might you choose a higher or lower value?\n",
        "\n",
        "\n",
        "7. Train & Evaluate\n",
        "\n",
        "# Train\n",
        "from transformers import Trainer\n",
        "# you need to have your wandb api key ready to paste in the command line\n",
        "trainer = Trainer(\n",
        "    model=TODO,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "#Evaluate\n",
        "metrics = TODO\n",
        "print(metrics)\n",
        "# Expect something like: {\"eval_loss\": ..., \"eval_accuracy\": 0.98, ...}\n",
        "\n",
        "\n",
        "\n",
        "Interpret your results.\n"
      ],
      "metadata": {
        "id": "r-cQdG9tTqXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Étape 1 – Configuration de l’environnement"
      ],
      "metadata": {
        "id": "aYGsXXFvUbKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzP-2KmVZlQE",
        "outputId": "cdb86fe5-4c06-4352-c920-f8937bb17b03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "p-shoGD_Touy"
      },
      "outputs": [],
      "source": [
        "# Installation des dépendances\n",
        "!pip install --quiet evaluate transformers[sentencepiece]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 2 – Chargement et exploration du dataset SMS Spam\n",
        "\n"
      ],
      "metadata": {
        "id": "Ks9gz2JnUyuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Chargement du jeu de données \"sms_spam\" depuis HF Hub\n",
        "raw = load_dataset(\"ucirvine/sms_spam\")\n",
        "\n",
        "# Séparation du jeu (4000 entraînement, 1000 validation)\n",
        "train_ds = raw[\"train\"].shuffle(seed=42).select(range(4000))\n",
        "val_ds = raw[\"train\"].shuffle(seed=42).select(range(4000, 5000))\n",
        "\n",
        "# Affichage du schéma\n",
        "print(train_ds.features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtrO4gMAUxdT",
        "outputId": "8fde5217-8f19-4e14-d31d-c027d20ed32a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sms': Value('string'), 'label': ClassLabel(names=['ham', 'spam'])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement du dataset réussie :\n",
        "📨 \"sms\" est la colonne contenant les messages.\n",
        "\n",
        "🏷️ \"label\" est la colonne contenant les classes ham (0) et spam (1).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IReIk6hqbzFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3 — Tokenization pour GPT-2"
      ],
      "metadata": {
        "id": "kvSrTArDdCsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Nom du modèle pré-entraîné (de base)\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# Chargement du tokenizer GPT-2\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 💡 GPT-2 ne possède pas de token de padding → on utilise le token de fin\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Fonction de tokenization : transforme chaque message en input_ids + attention_mask\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"sms\"],            # le texte du SMS\n",
        "        padding=\"max_length\",       # on remplit à la même taille (obligatoire pour batching)\n",
        "        truncation=True,            # on coupe s'il dépasse\n",
        "        max_length=64               # taille max courte car ce sont des SMS\n",
        "    )\n",
        "\n",
        "# Application de la fonction sur chaque message du jeu d'entraînement et de validation\n",
        "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
        "val_tok   = val_ds.map(tokenize_fn, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e54030ee06194660afa16290e9de4a10",
            "e5b34e692a9d403e80fdca3981a2379c",
            "a2e2647844d94a58a56ff67b98dbce7b",
            "2767e2bd8b034382866ab07a701315b2",
            "8f0d18c3bc2b4b13999cd16b98128b0d",
            "e418f8beb9654e74ae724f27331db57b",
            "805817e127ea4b2aa144e0bfb27d64c3",
            "bf9cfdb285b64ae99ccabb01ce213be9",
            "2fc0a3a1494c48858c2cc59ed7135e49",
            "981f1bf39fc74df6bdf9b69198848214",
            "e64aeef743244591b066a5e6b5232713",
            "386da149ca8049e6a871cf68ddeeb4ca",
            "9527193f827f4929a7619ec73f759487",
            "3ce63047cc004e3bb35ebc9816102b23",
            "30585fafb71d4cb69c3195ef1310bdee",
            "317e1d9633d440cca2a49d068323890c",
            "1a481589d4484153a1b9710266b0aea4",
            "3c97ebc959c44657b730b4ec6219a084",
            "6b1a7acb1b8846b583cd484766a0e386",
            "3026b91cc3cd49849327cae6223cd5e1",
            "c970637b8263426f93aa0efb631be5e8",
            "57f0ae01209542ab909ad7c3b6e4b055"
          ]
        },
        "id": "8wn0uOjPdxY8",
        "outputId": "1e76af80-2253-43eb-968b-05770bf0e7d8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e54030ee06194660afa16290e9de4a10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "386da149ca8049e6a871cf68ddeeb4ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Résultat de la Tokenization :\n",
        "\n",
        "| Élément                    | Description                                                               |\n",
        "| -------------------------- | ------------------------------------------------------------------------- |\n",
        "| 📦 `tokenizer`             | C’est le **tokenizer GPT-2**, préentraîné avec un vocabulaire spécifique. |\n",
        "| ✅ Padding                  | J'ai utilisé `eos_token` comme `pad_token` (GPT-2 n’a pas de PAD natif). |\n",
        "| ✂️ Truncation              | Limité chaque SMS à 64 tokens max (largement suffisant pour des SMS).     |\n",
        "| 🗂️ Tokenisation appliquée | Aux **4000 SMS d’entraînement** et aux **1000 SMS de validation**.        |\n"
      ],
      "metadata": {
        "id": "Y0s_9VaMeiyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher quelques exemples tokenisés\n",
        "train_tok[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O6C-fuvQeNvc",
        "outputId": "ad971945-5f85-4780-c583-bd8c938016de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sms': 'sports fans - get the latest sports news str* 2 ur mobile 1 wk FREE PLUS a FREE TONE Txt SPORT ON to 8007 www.getzed.co.uk 0870141701216+ norm 4txt/120p \\n',\n",
              " 'label': 1,\n",
              " 'input_ids': [32945,\n",
              "  3296,\n",
              "  532,\n",
              "  651,\n",
              "  262,\n",
              "  3452,\n",
              "  5701,\n",
              "  1705,\n",
              "  965,\n",
              "  9,\n",
              "  362,\n",
              "  2956,\n",
              "  5175,\n",
              "  352,\n",
              "  266,\n",
              "  74,\n",
              "  17189,\n",
              "  48635,\n",
              "  257,\n",
              "  17189,\n",
              "  309,\n",
              "  11651,\n",
              "  309,\n",
              "  742,\n",
              "  6226,\n",
              "  9863,\n",
              "  6177,\n",
              "  284,\n",
              "  10460,\n",
              "  22,\n",
              "  7324,\n",
              "  13,\n",
              "  1136,\n",
              "  8863,\n",
              "  13,\n",
              "  1073,\n",
              "  13,\n",
              "  2724,\n",
              "  657,\n",
              "  5774,\n",
              "  28645,\n",
              "  1558,\n",
              "  486,\n",
              "  20666,\n",
              "  10,\n",
              "  2593,\n",
              "  604,\n",
              "  14116,\n",
              "  14,\n",
              "  10232,\n",
              "  79,\n",
              "  220,\n",
              "  198,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256,\n",
              "  50256],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 4 – Initialiser le modèle GPT-2 avec une tête de classification\n",
        "l'Objectif est d'initialiser GPT-2 avec une tête de classification binaire (spam ou ham). GPT-2 est à l’origine un modèle de génération de texte, donc je  dois l’adapter pour une tâche de classification."
      ],
      "metadata": {
        "id": "5nVTI0lHiYRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Import du modèle de classification basé sur GPT-2\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "model_name = \"gpt2\"\n",
        "# 🎯 On initialise GPT-2 avec une \"classification head\"\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\n",
        "    model_name,             # 'gpt2' ou autre si tu veux un modèle plus gros\n",
        "    num_labels=2,           # 0 = ham, 1 = spam → classification binaire\n",
        "    pad_token_id=tokenizer.eos_token_id  # nécessaire pour éviter des erreurs avec le padding\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCPJ7Wq6iuEc",
        "outputId": "41af1997-05fa-424e-b848-fd3e1f99a5a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuR6HbLmjWH1",
        "outputId": "582a4fe7-ec73-4878-efb2-a4f1eadfa156"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2ForSequenceClassification(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##✅ Étape 5 : Définir les métriques d’évaluation.\n"
      ],
      "metadata": {
        "id": "qr83eXBRmU1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate        # bibliothèque Hugging Face pour les métriques standards\n",
        "import numpy as np     # nécessaire pour le traitement des logits\n",
        "\n",
        "# 📈 Chargement des métriques depuis evaluate\n",
        "accuracy  = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall    = evaluate.load(\"recall\")\n",
        "f1        = evaluate.load(\"f1\")\n",
        "\n",
        "# 🧮 Fonction de calcul des métriques, appelée automatiquement à chaque évaluation\n",
        "def compute_metrics(pred):\n",
        "    logits, labels = pred                     # prédictions brutes du modèle (logits) et vraies étiquettes\n",
        "    preds = np.argmax(logits, axis=-1)        # on convertit les logits en classes prédites (0 ou 1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\":  accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"],\n",
        "        \"recall\":    recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
        "        \"f1\":        f1.compute(predictions=preds, references=labels)[\"f1\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "8nsy_etYmaOF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Étape 6 – TrainingArguments\n",
        "\n",
        "L'objectif est de configurerles hyperparamètres de l’entraînement, comme le batch size, le taux d’apprentissage, la fréquence d’évaluation, etc."
      ],
      "metadata": {
        "id": "ntNozN-mmu9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",        # 📂 Où sauvegarder les checkpoints du modèle\n",
        "\n",
        "    do_train=True,                 # ✅ Active l'entraînement\n",
        "    do_eval=True,                  # ✅ Active l'évaluation pendant l'entraînement\n",
        "\n",
        "    eval_steps=500,                # 🧪 Évaluer toutes les 500 étapes\n",
        "    save_steps=500,                # 💾 Sauvegarder un checkpoint toutes les 500 étapes\n",
        "    logging_steps=500,             # 🪵 Journaliser les métriques toutes les 500 étapes\n",
        "\n",
        "    per_device_train_batch_size=8,     # 📦 Nombre d'exemples par lot en entraînement\n",
        "    per_device_eval_batch_size=8,      # 📦 Idem pour validation\n",
        "    num_train_epochs=3,                # 🔁 Nombre de fois qu'on passe sur le jeu d'entraînement\n",
        "\n",
        "    learning_rate=5e-5,            # ⚙️ Taux d'apprentissage\n",
        "    weight_decay=0.01,             # 🧽 Régularisation L2 pour éviter le surapprentissage\n",
        "\n",
        "    report_to=[],                # 🚫 Désactiver WandB, TensorBoard, etc. (à activer si besoin)\n",
        "    save_total_limit=1             # 🔁 Ne garder que le dernier checkpoint\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "vuqmBsllmz6F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Étape 7 : Entraîner et évaluer le modèle avec Trainer"
      ],
      "metadata": {
        "id": "yP38AhiTnlKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# 🧠 Crée le Trainer avec tous les éléments nécessaires\n",
        "trainer = Trainer(\n",
        "    model=model,                        # 🎯 le modèle GPT-2 à entraîner\n",
        "    args=training_args,                # ⚙️ les hyperparamètres définis précédemment\n",
        "    train_dataset=train_tok,           # 📊 dataset d'entraînement tokenisé\n",
        "    eval_dataset=val_tok,              # 📊 dataset de validation tokenisé\n",
        "    compute_metrics=compute_metrics    # 📏 fonction pour évaluer le modèle\n",
        ")\n",
        "\n",
        "# 🚀 Lancement de l'entraînement\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fh5Fy-wenzmG",
        "outputId": "44049ce4-d4c0-4473-cb1a-1abaa19613bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 05:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.118700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.009500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=0.0557409995396932, metrics={'train_runtime': 305.9798, 'train_samples_per_second': 39.218, 'train_steps_per_second': 4.902, 'total_flos': 391945125888000.0, 'train_loss': 0.0557409995396932, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évaluer sur le set de validation"
      ],
      "metadata": {
        "id": "lr7sjC8Tn5W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 Évaluation finale sur le dataset de validation\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "# 📢 Affichage des résultats\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "AQaNGNwKn9Gl",
        "outputId": "e23ed12a-cdda-4279-a227-5821148c1a3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.037382956594228745, 'eval_accuracy': 0.995, 'eval_precision': 0.9831932773109243, 'eval_recall': 0.975, 'eval_f1': 0.9790794979079498, 'eval_runtime': 4.0378, 'eval_samples_per_second': 247.658, 'eval_steps_per_second': 30.957, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interprétation métrique par métrique :\n",
        "\n",
        "| Métrique      | Résultat | Interprétation                                                                 |\n",
        "| ------------- | -------- | ------------------------------------------------------------------------------ |\n",
        "| **Loss**      | `0.037`  | Très faible, le modèle a bien appris à distinguer les classes                  |\n",
        "| **Accuracy**  | `99.5%`  | Très haut, montre que le modèle est globalement très fiable                    |\n",
        "| **Precision** | `98.3%`  | Peu de faux positifs → très peu de messages normaux détectés à tort comme spam |\n",
        "| **Recall**    | `97.5%`  | Peu de spams sont ratés (faux négatifs faibles)                                |\n",
        "| **F1-score**  | `97.9%`  | Excellent équilibre entre précision et rappel                                  |\n",
        "\n",
        "\n",
        "--> GPT-2 est entraîné avec succès pour la classification SMS et les résultats sont excellents.\n"
      ],
      "metadata": {
        "id": "IPI0vpLQs2RW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Conclusion\n",
        "Le modèle GPT-2 est fine-tuné :\n",
        "\n",
        "* Prédit les SMS spam avec très haute précision\n",
        "\n",
        "* Rate très peu de spams\n",
        "\n",
        "* Généralise bien sans surapprentissage apparent (vu le loss bas et l’équilibre des scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "jceFlQ3TtdHV"
      }
    }
  ]
}