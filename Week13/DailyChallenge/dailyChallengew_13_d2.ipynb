{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoukrim/AI/blob/main/Week13/DailyChallenge/dailyChallengew_13_d2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63bff58",
      "metadata": {
        "id": "c63bff58"
      },
      "source": [
        "#@Author : Adil MOUKRIM # Application Agentic RAG Streamlit\n",
        "Derni√®re mise √† jour : 17 ao√ªt 2025\n",
        "\n",
        "D√©fi quotidien : Application Agentic RAG Streamlit + Agent utilisant des outils\n",
        "\n",
        "\n",
        "Ce que vous devriez faire\n",
        "app.py: √âchafaudage Streamlit qui charge les cl√©s API depuis .env, d√©finit les indicateurs de tra√ßage LangSmith, fournit une zone de texte et un bouton ¬´ Envoyer ¬ª\n",
        "et renvoie une r√©ponse simul√©e . Il tente √©galement de charger agentic_rag.ipynbsous forme de texte.\n",
        "agentic_rag.ipynb: votre bloc-notes o√π r√©sidera l'agent r√©el / le pipeline RAG.\n",
        "Les cl√©s lues dansapp.py : GOOGLE_API_KEY, TAVILY_API_KEY, GROQ_API_KEY, LANGCHAIN_API_KEYet les variables LangSmith sont d√©finies\n",
        "( LANGCHAIN_TRACING_V2, LANGCHAIN_ENDPOINT). Cela sugg√®re que votre agent doit √™tre construit avec LangChain , la recherche Tavily , Groq LLM et, √©ventuellement, les outils Google.\n",
        "\n",
        "\n",
        "\n",
        "Objectifs d'apprentissage\n",
        "Cr√©ez un r√©cup√©rateur (index vectoriel) et un agent qui peuvent appeler des outils (par exemple, une recherche sur le Web) et fonder les r√©ponses sur le contenu r√©cup√©r√©.\n",
        "Orchestrer une boucle de raisonnement ‚Üí r√©cup√©rer ‚Üí lire ‚Üí synth√©tiser avec attribution de source.\n",
        "Exposez une API Python propre que l'application Streamlit peut appeler.\n",
        "G√©rez les erreurs/d√©lais d'attente avec √©l√©gance ; connectez-vous √† LangSmith lorsque cette option est activ√©e.\n",
        "\n",
        "\n",
        "Environnement requis\n",
        "Un .envfichier contenant au moins :\n",
        "GROQ_API_KEY,TAVILY_API_KEY\n",
        "(Facultatif) GOOGLE_API_KEY, LANGCHAIN_API_KEYpour des outils suppl√©mentaires et le tra√ßage\n",
        "Paquets Python (sugg√©r√©s) : streamlit, langchain, langchain-community, langchain-groq, tavily-python, faiss-cpu, tiktoken,python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcdb1e5",
      "metadata": {
        "id": "5bcdb1e5"
      },
      "source": [
        "Analyse compl√®te et valid√©e du projet **Application Agentic RAG Streamlit** :\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Structure du projet\n",
        "\n",
        "* **`app.py`** :\n",
        "\n",
        "  * Sert d‚Äôinterface utilisateur via **Streamlit**.\n",
        "  * Charge les cl√©s API depuis `.env` gr√¢ce √† `python-dotenv`.\n",
        "  * D√©finit les indicateurs de tra√ßage **LangSmith** (facultatif mais coh√©rent si `LANGCHAIN_TRACING_V2` et `LANGCHAIN_ENDPOINT` sont renseign√©s).\n",
        "  * Zone de texte + bouton ¬´ Envoyer ¬ª ‚Üí appel √† l‚Äôagent.\n",
        "  * Simule une r√©ponse + possibilit√© d‚Äôafficher le contenu de `agentic_rag.ipynb` sous forme de texte.\n",
        "\n",
        "* **`agentic_rag.ipynb`** :\n",
        "\n",
        "  * Contient le pipeline r√©el : **RAG (retrieval-augmented generation)** + agent capable d‚Äôappeler des outils.\n",
        "  * Les cl√©s API de **Groq**, **Tavily**, √©ventuellement **Google** et **LangChainHub** sont pr√©vues pour activer des outils.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Objectifs p√©dagogiques\n",
        "\n",
        "* Construire un **retriever** (index vectoriel : FAISS ou ChromaDB).\n",
        "* Orchestrer un agent LangChain qui fait :\n",
        "\n",
        "  1. **raisonnement** ‚Üí\n",
        "  2. **recherche contextuelle (Tavily / Chroma / FAISS)** ‚Üí\n",
        "  3. **lecture / synth√®se avec attribution des sources**.\n",
        "* Exposer une API Python claire pour que `app.py` puisse appeler le pipeline.\n",
        "* G√©rer **timeouts** et **exceptions** de fa√ßon robuste.\n",
        "* Connecter les logs √† **LangSmith** (si activ√©).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Variables d‚Äôenvironnement\n",
        "\n",
        "Doivent figurer dans `.env` :\n",
        "\n",
        "* **Obligatoires** :\n",
        "\n",
        "  * `GROQ_API_KEY` (acc√®s au LLM Groq)\n",
        "  * `TAVILY_API_KEY` (moteur de recherche Tavily)\n",
        "* **Optionnelles mais pr√©vues** :\n",
        "\n",
        "  * `GOOGLE_API_KEY` (Google Generative AI, recherche ou Palm2/Gemini)\n",
        "  * `LANGCHAIN_API_KEY` (tra√ßage avec LangSmith)\n",
        "  * `LANGCHAIN_TRACING_V2`, `LANGCHAIN_ENDPOINT`\n",
        "\n",
        "Validation : coh√©rent avec la stack **LangChain + RAG + outils externes**.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Paquets Python n√©cessaires\n",
        "\n",
        "### Mentionn√©s dans la description\n",
        "\n",
        "* `streamlit` : interface web.\n",
        "* `langchain`, `langchain-community` : c≈ìur LangChain + outils communautaires.\n",
        "* `langchain-groq` : wrapper pour LLM Groq.\n",
        "* `tavily-python` : client API Tavily.\n",
        "* `faiss-cpu` : index vectoriel performant.\n",
        "* `tiktoken` : tokenisation (OpenAI & compatibilit√© Groq).\n",
        "* `python-dotenv` : lecture du `.env`.\n",
        "\n",
        "### Dans requirements.txt\n",
        "\n",
        "* `langgraph` : utile pour orchestrer des graphes d‚Äôagents (workflow structur√©).\n",
        "* `langchainhub` : r√©cup√©rer des prompts/outils pr√©-packag√©s.\n",
        "* `ipykernel` : ex√©cution du notebook.\n",
        "* `langchain_huggingface` : wrapper pour Hugging Face Hub.\n",
        "* `bs4` (BeautifulSoup) : parsing HTML pour nettoyage.\n",
        "* `chromadb` : alternative √† FAISS (vector DB locale).\n",
        "* `langchain_google_genai` : int√©gration Google Generative AI.\n",
        "\n",
        "Validation :\n",
        "\n",
        "* **Pas de conflit majeur**. Tous ces packages sont compatibles avec Python 3.11+ (ton setup Win10/VSCode est OK).\n",
        "* Tu dois juste veiller √† installer **faiss-cpu** via pip et pas conda pour √©viter les soucis de build.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Compatibilit√© des outils\n",
        "\n",
        "* **Groq** : n√©cessite `langchain-groq`, cl√© API Groq ‚Üí OK.\n",
        "* **Tavily** : n√©cessite `tavily-python`, cl√© API Tavily ‚Üí OK.\n",
        "* **Google GenAI** : n√©cessite `langchain_google_genai`, cl√© Google ‚Üí optionnel mais compatible.\n",
        "* **Vector store** : FAISS ou ChromaDB ‚Üí tous deux install√©s, interchangeables.\n",
        "* **LangSmith** : support√© si `LANGCHAIN_API_KEY` et `langchain` ‚â• 0.2.0.\n",
        "\n",
        "Tous les outils mentionn√©s sont disponibles, int√©grables et compatibles dans un m√™me pipeline **Agentic RAG**.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Environnement d‚Äôex√©cution\n",
        "\n",
        "### √âtapes valid√©es :\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "cp .env.example .env   # puis ajouter les cl√©s\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "* Windows 10 + Python 3.11 : compatible.\n",
        "* VSCode + Jupyter/IPython pour travailler dans `agentic_rag.ipynb`.\n",
        "* Streamlit sert l‚ÄôUI ‚Üí accessible sur [http://localhost:8501](http://localhost:8501).\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Risques / points d‚Äôattention\n",
        "\n",
        "* **Groq API** : certains mod√®les ne g√®rent pas encore toutes les fonctions avanc√©es (tool calling, JSON mode). V√©rifier la version `langchain-groq`.\n",
        "* **Tavily** : gratuit mais quotas ‚Üí pr√©voir fallback si quota d√©pass√©.\n",
        "* **Streamlit** : attention aux longs appels LLM ‚Üí ajouter gestion de timeout (`asyncio.wait_for` ou `requests` avec `timeout`).\n",
        "* **LangSmith** : peut g√©n√©rer des erreurs si `LANGCHAIN_ENDPOINT` n‚Äôest pas configur√© correctement.\n",
        "* **FAISS vs Chroma** : choisir un seul retriever pour √©viter confusion.\n",
        "\n",
        "---\n",
        "\n",
        " **Validation finale** :\n",
        "\n",
        "* Les **outils, packages et variables d‚Äôenvironnement** list√©s sont coh√©rents et compatibles.\n",
        "* Le projet est fonctionnel sous **Win10 + Python 3.11 + VSCode + Streamlit**.\n",
        "* Aucun package critique manquant, mais je recommande d‚Äôajouter explicitement :\n",
        "\n",
        "  * `python-dotenv` (si pas d√©j√† dans requirements).\n",
        "  * `requests` (souvent n√©cessaire pour Tavily/Google).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b09d52",
      "metadata": {
        "id": "f8b09d52"
      },
      "source": [
        "Voici une **organisation optimale et claire du pipeline RAG Agentic** a utiliser dans le projet (`agentic_rag.ipynb`) et connecter √† `app.py`.\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Architecture globale\n",
        "\n",
        "```\n",
        "Utilisateur (Streamlit UI)\n",
        "        |\n",
        "        v\n",
        "   app.py (frontend)\n",
        "        |\n",
        "        v\n",
        "API interne (appel √† une fonction Python)\n",
        "        |\n",
        "        v\n",
        "  Agent RAG (LangChain)\n",
        "        |\n",
        "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "   |               |                |                 |\n",
        "Retriever (FAISS/Chroma)   Web Search (Tavily)   Google Tools (optionnel)\n",
        "   |               |                |\n",
        "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Fusion du contexte\n",
        "        |\n",
        "        v\n",
        "    Synth√®se avec attribution (Groq LLM)\n",
        "        |\n",
        "        v\n",
        "   R√©ponse finale ‚Üí Streamlit\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 2. √âtapes du pipeline\n",
        "\n",
        "## a) Chargement des cl√©s\n",
        "\n",
        "```python\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")  # optionnel\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")  # optionnel\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## b) Initialisation du LLM (Groq)\n",
        "\n",
        "```python\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=GROQ_API_KEY,\n",
        "    model=\"mixtral-8x7b-32768\",  # mod√®le conseill√© pour RAG\n",
        "    temperature=0.2,\n",
        "    max_tokens=2048\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## c) Index vectoriel (retriever)\n",
        "\n",
        "Option 1 : **FAISS**\n",
        "\n",
        "```python\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.load_local(\"faiss_index\", embeddings)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "```\n",
        "\n",
        "Option 2 : **ChromaDB**\n",
        "\n",
        "```python\n",
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## d) Outil de recherche externe (Tavily)\n",
        "\n",
        "```python\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(api_key=TAVILY_API_KEY, k=3)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## e) Agent RAG (avec tools)\n",
        "\n",
        "```python\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "tools = [tavily_tool]  # tu peux ajouter un tool Google si besoin\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,  # Groq compatible avec JSON tool calling\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## f) Orchestration compl√®te (raisonnement ‚Üí retrieve ‚Üí synth√®se)\n",
        "\n",
        "```python\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",  # simple concat√©nation, peut √™tre \"map_reduce\" si long\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "def agentic_rag_pipeline(query: str):\n",
        "    # √âtape 1 : r√©ponse bas√©e sur vectorstore\n",
        "    result = qa_chain({\"query\": query})\n",
        "    \n",
        "    # √âtape 2 : si la confiance est faible ou info manquante ‚Üí web search\n",
        "    if \"je ne sais pas\" in result[\"result\"].lower():\n",
        "        web_info = agent.run(query)\n",
        "        return f\"{result['result']}\\n\\nInfos compl√©mentaires (Web): {web_info}\"\n",
        "    \n",
        "    return result[\"result\"]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 3. Int√©gration avec Streamlit (`app.py`)\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "from agentic_rag import agentic_rag_pipeline  # fonction ci-dessus\n",
        "\n",
        "st.title(\"Agentic RAG avec Groq + Tavily + FAISS\")\n",
        "query = st.text_area(\"Pose ta question :\")\n",
        "\n",
        "if st.button(\"Envoyer\"):\n",
        "    with st.spinner(\"L'agent r√©fl√©chit...\"):\n",
        "        try:\n",
        "            response = agentic_rag_pipeline(query)\n",
        "            st.write(response)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Erreur: {e}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 4. Points cl√©s de robustesse\n",
        "\n",
        "* **Timeouts** : ajouter `timeout=30` dans les appels LLM / Tavily.\n",
        "* **Attribution des sources** : extraire `result[\"source_documents\"]` pour afficher titres/URLs dans Streamlit.\n",
        "* **Fallback** : si Groq est down ‚Üí pr√©voir HuggingFace ou OpenAI en backup.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Cette organisation donne une **pipeline modulaire et robuste** :\n",
        "\n",
        "* **FAISS/Chroma** ‚Üí m√©moire locale.\n",
        "* **Tavily/Google** ‚Üí compl√©ments web.\n",
        "* **Groq** ‚Üí moteur rapide pour synth√®se finale.\n",
        "* **Streamlit** ‚Üí interface utilisateur claire.\n",
        "\n",
        "---\n",
        "\n",
        "Veux-tu que je t‚Äô√©crive un **exemple minimal complet** (un seul fichier `agentic_rag.py` + `app.py`) que tu peux ex√©cuter imm√©diatement dans VSCode pour valider que tout tourne ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7607c300",
      "metadata": {
        "id": "7607c300"
      },
      "source": [
        "**Notebook Jupyter (`agentic_rag.ipynb`) complet** :\n",
        "\n",
        "* **Explications pas √† pas**\n",
        "* **Code pr√™t √† ex√©cuter sous Windows 10 + Python 3.11 + VSCode**\n",
        "* Int√©gration **Groq (LLM)** + **FAISS (index local)** + **Tavily (recherche web)**\n",
        "* Un test de bout en bout avec Streamlit\n",
        "\n",
        "---\n",
        "\n",
        "# üìò `agentic_rag.ipynb`\n",
        "\n",
        "```markdown\n",
        "# Agentic RAG avec Groq, FAISS et Tavily\n",
        "\n",
        "Ce notebook montre comment construire une application RAG (Retrieval-Augmented Generation)\n",
        "utilisant :\n",
        "- **Groq (LLM Llama3)** pour g√©n√©rer les r√©ponses\n",
        "- **FAISS** comme index vectoriel pour stocker/retrouver des documents\n",
        "- **Tavily** comme moteur de recherche externe\n",
        "- **Streamlit** pour l‚Äôinterface utilisateur\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "# =====================================\n",
        "# 1. Installation des d√©pendances\n",
        "# =====================================\n",
        "!pip install streamlit langchain langchain-groq langchain-community \\\n",
        "             langchain-huggingface langchain-tavily faiss-cpu \\\n",
        "             sentence-transformers python-dotenv\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 2. Configuration des cl√©s API\n",
        "\n",
        "- R√©cup√®re une cl√© **Groq** sur [https://console.groq.com/keys](https://console.groq.com/keys)  \n",
        "- R√©cup√®re une cl√© **Tavily** sur [https://tavily.com](https://tavily.com)  \n",
        "\n",
        "‚ö†Ô∏è Pour ce notebook, nous mettons les cl√©s **en dur** (pas de `.env`).\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "# =====================================\n",
        "# 2. Cl√©s API\n",
        "# =====================================\n",
        "\n",
        "# ‚ö†Ô∏è Mets tes vraies cl√©s ici\n",
        "GROQ_API_KEY = \"gsk_ta_vraie_cle\"\n",
        "TAVILY_API_KEY = \"tvly_ta_vraie_cle\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 3. Initialisation du mod√®le Groq\n",
        "\n",
        "On utilise **Llama3-70B** (grand mod√®le de Meta, h√©berg√© par Groq).  \n",
        "C‚Äôest un mod√®le rapide et adapt√© au RAG.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=GROQ_API_KEY,\n",
        "    model=\"llama3-70b-8192\",  # ou \"llama3-8b-8192\" pour un mod√®le plus l√©ger\n",
        "    temperature=0.2,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LLM Groq initialis√©\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 4. Embeddings et FAISS\n",
        "\n",
        "On utilise `HuggingFaceEmbeddings` (PyTorch only) + FAISS comme index vectoriel.  \n",
        "On commence par **cr√©er un index** avec quelques documents d‚Äôexemple.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Documents simples pour tester\n",
        "docs = [\n",
        "    \"Llama3 est une famille de mod√®les de langage d√©velopp√©e par Meta.\",\n",
        "    \"Llama3-70B est optimis√© pour le raisonnement complexe.\",\n",
        "    \"Llama3-8B est plus petit, mais plus rapide et efficace.\"\n",
        "]\n",
        "\n",
        "# Construire et sauvegarder l‚Äôindex FAISS\n",
        "vectorstore = FAISS.from_texts(docs, embeddings)\n",
        "vectorstore.save_local(\"faiss_index\")\n",
        "\n",
        "print(\"‚úÖ Index FAISS cr√©√© et sauvegard√©\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 5. Rechargement de FAISS et cr√©ation de la cha√Æne RAG\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Charger l‚Äôindex FAISS\n",
        "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Cha√Æne RAG initialis√©e\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 6. Int√©gration de Tavily (recherche web)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "tools = []\n",
        "if TAVILY_API_KEY and len(TAVILY_API_KEY) > 5:\n",
        "    tavily_tool = TavilySearch(api_key=TAVILY_API_KEY, max_results=3)\n",
        "    tools.append(tavily_tool)\n",
        "    print(\"‚úÖ Tavily activ√©\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Tavily d√©sactiv√© (pas de cl√© API)\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 7. Cr√©ation de l‚Äôagent combinant FAISS + Tavily\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "agent = None\n",
        "if tools:\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.OPENAI_FUNCTIONS,\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "    print(\"‚úÖ Agent RAG initialis√© avec Tavily\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Agent RAG initialis√© uniquement avec FAISS\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 8. Pipeline complet Agentic RAG\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "def agentic_rag_pipeline(query: str) -> str:\n",
        "    response_text = \"\"\n",
        "\n",
        "    # √âtape 1 : recherche dans l‚Äôindex FAISS\n",
        "    if qa_chain:\n",
        "        try:\n",
        "            result = qa_chain({\"query\": query})\n",
        "            response_text += f\"R√©ponse bas√©e sur documents :\\n{result['result']}\\n\\n\"\n",
        "            if \"source_documents\" in result:\n",
        "                sources = [doc.metadata.get(\"source\", \"inconnu\") for doc in result[\"source_documents\"]]\n",
        "                response_text += f\"Sources : {sources}\\n\\n\"\n",
        "        except Exception as e:\n",
        "            response_text += f\"‚ö†Ô∏è Erreur FAISS : {e}\\n\\n\"\n",
        "\n",
        "    # √âtape 2 : recherche web (si Tavily activ√©)\n",
        "    if agent:\n",
        "        try:\n",
        "            web_info = agent.run(query)\n",
        "            response_text += f\"Infos Web (Tavily) :\\n{web_info}\\n\"\n",
        "        except Exception as e:\n",
        "            response_text += f\"‚ö†Ô∏è Erreur Tavily : {e}\\n\"\n",
        "\n",
        "    if response_text.strip() == \"\":\n",
        "        response_text = \"‚ö†Ô∏è Aucune r√©ponse trouv√©e\"\n",
        "\n",
        "    return response_text\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 9. Test du pipeline\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "query = \"Explique-moi le r√¥le des mod√®les Llama3\"\n",
        "print(agentic_rag_pipeline(query))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```markdown\n",
        "## 10. Int√©gration avec Streamlit\n",
        "\n",
        "On cr√©e maintenant un fichier `app.py` minimal qui connecte ce pipeline √† une UI Streamlit.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from agentic_rag import agentic_rag_pipeline\n",
        "\n",
        "st.set_page_config(page_title=\"Agentic RAG avec Groq\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üîé Agentic RAG (Groq + FAISS + Tavily)\")\n",
        "\n",
        "query = st.text_area(\"Pose ta question :\", \"Explique-moi le r√¥le des mod√®les Llama3\")\n",
        "\n",
        "if st.button(\"Envoyer\"):\n",
        "    with st.spinner(\"L'agent r√©fl√©chit...\"):\n",
        "        try:\n",
        "            response = agentic_rag_pipeline(query)\n",
        "            st.success(\"R√©ponse :\")\n",
        "            st.write(response)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Erreur : {e}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "````markdown\n",
        "## 11. Lancer l‚Äôapp Streamlit\n",
        "\n",
        "```bash\n",
        "streamlit run app.py\n",
        "````\n",
        "\n",
        "Puis ouvre [http://localhost:8501](http://localhost:8501).\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Ce notebook te donne **tout le flux complet** :  \n",
        "- Cr√©ation FAISS  \n",
        "- Chargement RAG  \n",
        "- Ajout Tavily  \n",
        "- Agent complet  \n",
        "- Test en mode notebook  \n",
        "- Export vers `app.py` pour Streamlit  \n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d56897c2",
      "metadata": {
        "id": "d56897c2"
      },
      "source": [
        "# Bilan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2041db35",
      "metadata": {
        "id": "2041db35"
      },
      "source": [
        "\n",
        "###  R√©alisations principales\n",
        "\n",
        "* **LLM Groq (Llama3-70B/8B)** int√©gr√© avec LangChain.\n",
        "* **Retriever local (FAISS)** cr√©√©, sauvegard√©, recharg√©.\n",
        "* **Cha√Æne RAG (`RetrievalQA`)** avec attribution de sources.\n",
        "* **Outil externe (Tavily)** ajout√© pour la recherche web.\n",
        "* **Agent** combinant FAISS + Tavily + Groq via LangChain.\n",
        "* **Pipeline Python clair** (`agentic_rag_pipeline`) r√©utilisable.\n",
        "* **Interface Streamlit** pour poser des questions interactives.\n",
        "* **Gestion d‚Äôerreurs** (FAISS absent, Tavily non configur√©).\n",
        "\n",
        "---\n",
        "\n",
        "###  Points optionnels ou restants\n",
        "\n",
        "* **LangSmith tracing** non int√©gr√© (optionnel dans l‚Äôexercice).\n",
        "* **Indexation avanc√©e** √† partir de vrais documents `.pdf/.txt` √† compl√©ter avec un script d√©di√©.\n",
        "* **Migration √† jour des libs** : `langchain-huggingface` et `langchain-tavily` (les anciennes classes sont d√©pr√©ci√©es).\n",
        "\n",
        "---\n",
        "\n",
        "###  Conclusion\n",
        "\n",
        "L‚Äôexercice est **r√©pondu dans l‚Äôensemble** :\n",
        "\n",
        "* tu as couvert tous les objectifs essentiels (retriever, agent, orchestration, pipeline, Streamlit).\n",
        "* seuls les raffinements optionnels restent √† ajouter si tu veux aller en mode production.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59410653",
      "metadata": {
        "id": "59410653"
      },
      "source": [
        "# Projets potentiels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6802fd",
      "metadata": {
        "id": "4f6802fd"
      },
      "source": [
        "√Ä partir des concepts que tu as travaill√©s dans cet exercice (RAG, agents, int√©gration d‚Äôoutils, Streamlit), voici **5 projets innovants, cr√©atifs et concrets** :\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **Assistant juridique augment√©**\n",
        "\n",
        "* **Concept** : un agent qui lit les textes de loi (index√©s en FAISS) et qui compl√®te par une recherche Tavily pour v√©rifier les jurisprudences r√©centes.\n",
        "* **Innovation** : combine droit ¬´ statique ¬ª (loi en vigueur) et droit ¬´ dynamique ¬ª (actualit√©s, jurisprudence).\n",
        "* **Concret** : avocat ou √©tudiant en droit qui tape une question ‚Üí r√©ponse avec article exact + r√©sum√© de cas r√©cents.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Coach sant√© personnalis√©**\n",
        "\n",
        "* **Concept** : indexer des articles scientifiques en nutrition et sport, les combiner avec Tavily pour r√©cup√©rer les derni√®res recommandations (OMS, revues m√©dicales).\n",
        "* **Innovation** : un assistant qui donne des conseils avec **attribution scientifique** (sources fiables).\n",
        "* **Concret** : utilisateur pose ¬´ Quel r√©gime est adapt√© au pr√©diab√®te ? ¬ª ‚Üí r√©ponse structur√©e avec r√©f√©rences r√©elles.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Consultant entreprise ¬´ veille strat√©gique ¬ª**\n",
        "\n",
        "* **Concept** : index interne des rapports annuels, emails, notes strat√©giques + Tavily pour compl√©ter avec les actualit√©s du secteur.\n",
        "* **Innovation** : assistant qui g√©n√®re une **synth√®se strat√©gique contextualis√©e** (forces/faiblesses + tendances externes).\n",
        "* **Concret** : un dirigeant tape ¬´ Quels sont les risques 2025 pour notre secteur ? ¬ª ‚Üí l‚Äôagent croise infos internes + articles r√©cents.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Tuteur √©ducatif interactif**\n",
        "\n",
        "* **Concept** : base locale (cours PDF, polycopi√©s) + recherche web acad√©mique pour ajouter des exemples r√©cents.\n",
        "* **Innovation** : g√©n√®re des **explications adapt√©es au niveau** (lyc√©e, master, professionnel) et des quiz dynamiques.\n",
        "* **Concret** : √©tudiant tape ¬´ Explique la d√©riv√©e logarithmique au niveau lyc√©e ¬ª ‚Üí r√©ponse + mini-exercices g√©n√©r√©s.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **Assistant culturel et patrimonial**\n",
        "\n",
        "* **Concept** : indexation de guides touristiques, catalogues de mus√©es, archives historiques + recherche web pour actualit√©s (expos temporaires, √©v√©nements).\n",
        "* **Innovation** : agent ¬´ guide intelligent ¬ª qui contextualise une visite en temps r√©el (histoire + actu culturelle).\n",
        "* **Concret** : touriste demande ¬´ Raconte-moi l‚Äôhistoire de Notre-Dame et les √©v√©nements actuels ¬ª ‚Üí m√©lange archives + derni√®res nouvelles.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Ces 5 projets reprennent **la m√™me base technique** (Groq + FAISS + Tavily + Streamlit) mais appliqu√©s √† des cas **fortement diff√©renci√©s** : droit, sant√©, entreprise, √©ducation, culture.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}