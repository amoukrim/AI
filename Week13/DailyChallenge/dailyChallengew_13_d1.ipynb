{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoukrim/AI/blob/main/Week13/DailyChallenge/dailyChallengew_13_d1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7bcedf",
      "metadata": {
        "id": "bc7bcedf"
      },
      "source": [
        "#@ Adil MOUKRIM\n",
        "\n",
        "# HTTP Web Search Briefing Bot\n",
        "Last Updated: August 11th, 2025\n",
        "\n",
        "Daily Challenge : HTTP Web Search Briefing Bot\n",
        "\n",
        "\n",
        "üõ†Ô∏è What you will create\n",
        "An HTTP server that exposes a tiny ‚Äútool‚Äù API for web search + page fetching + LLM summarization, plus a small CLI client that triggers the flow end‚Äëto‚Äëend and saves a Markdown briefing with citations.\n",
        "\n",
        "\n",
        "Learning objectives\n",
        "Design a clean HTTP API that a client can call (client/server separation).\n",
        "Use a free web search API to get results programmatically.\n",
        "Call a free local LLM over HTTP (Ollama or LM Studio) to summarize with inline citations.\n",
        "Implement basic input validation, timeouts, and error handling.\n",
        "Produce a reproducible README and a tiny automation client."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57202878",
      "metadata": {
        "id": "57202878"
      },
      "source": [
        "Analyse d√©taill√©e de l‚Äôexercice + **plan de r√©solution pas √† pas** 100% compatible VSCode, Windows 10, Python 3.11\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Analyse d√©taill√©e de l‚Äôexercice\n",
        "\n",
        "### Objectif final\n",
        "\n",
        "* D√©velopper un **serveur HTTP** qui expose une API JSON pour web search, extraction de contenu, r√©sum√© LLM, sauvegarde markdown.\n",
        "* D√©velopper un **client CLI** qui orchestre tout le flow (search ‚Üí fetch ‚Üí summarize ‚Üí save) et affiche le chemin du fichier markdown produit.\n",
        "* Fournir un README reproductible, exemples cURL/Postman, et un exemple de r√©sultat.\n",
        "\n",
        "### Contraintes fortes\n",
        "\n",
        "* **HTTP only** (pas de STDIO)\n",
        "* **Authentification Bearer simple**\n",
        "* **Pas de LLM cloud payant** : usage *obligatoire* d‚Äôun LLM local via API HTTP (Ollama ou LM Studio)\n",
        "* **Search API gratuite** obligatoire (Google CSE ou Tavily conseill√©)\n",
        "* **Setup < 10 min** sur un laptop typique\n",
        "* Fonctionnement local Windows 10 + Python 3.11 (exigence explicite)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Compatibilit√© et pr√©requis\n",
        "\n",
        "### Plateforme cible :\n",
        "\n",
        "* **VSCode** (parfait pour dev, debug, scripts Python)\n",
        "* **Windows 10** (attention aux chemins de fichiers, √† l‚Äôencoding, √† la gestion de subprocess)\n",
        "* **Python 3.11** (pas Node.js sauf pour LM Studio/Ollama qui tournent en dehors du projet Python)\n",
        "* **Git** (pour le README, versionnage, etc.)\n",
        "\n",
        "### APIs gratuites :\n",
        "\n",
        "* **Web search** : Google Custom Search API (CSE) ou Tavily\n",
        "* **LLM local HTTP** : Ollama conseill√© (plus facile √† installer, document√©, tourne en t√¢che de fond sur Windows/Mac/Linux)\n",
        "\n",
        "### Packages Python essentiels\n",
        "\n",
        "* `fastapi` ou `flask` (pour le serveur HTTP, FastAPI pr√©f√©rable pour la clart√© des schemas, mais Flask OK)\n",
        "* `requests` (pour appeler APIs tierces et le LLM local)\n",
        "* `pydantic` (pour validation des schemas d‚Äôentr√©e/sortie avec FastAPI)\n",
        "* `python-dotenv` (pour charger la cl√© Bearer et les secrets)\n",
        "* `rich` (pour un CLI agr√©able, optionnel)\n",
        "* `readability-lxml` (pour extraire le contenu lisible d‚Äôune page web)\n",
        "* `typer` ou `argparse` (pour le CLI)\n",
        "* **Pas de d√©pendances lourdes ni cloud payant**\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Plan de r√©solution **fonctionnel et complet**\n",
        "\n",
        "### **A. Initialisation de l‚Äôenvironnement**\n",
        "\n",
        "1. **Cr√©er le dossier projet**\n",
        "\n",
        "   ```\n",
        "   mkdir websearch-briefing-bot\n",
        "   cd websearch-briefing-bot\n",
        "   ```\n",
        "\n",
        "2. **Cr√©er et activer un venv**\n",
        "\n",
        "   ```\n",
        "   python -m venv .venv\n",
        "   .venv\\Scripts\\activate\n",
        "   ```\n",
        "\n",
        "3. **Installer les d√©pendances**\n",
        "\n",
        "   ```sh\n",
        "   pip install fastapi[all] requests python-dotenv readability-lxml typer\n",
        "   ```\n",
        "\n",
        "4. **Installer et lancer Ollama**\n",
        "\n",
        "   * T√©l√©charger Ollama : [https://ollama.com](https://ollama.com)\n",
        "   * Installer le mod√®le :\n",
        "\n",
        "     ```\n",
        "     ollama run llama3\n",
        "     ```\n",
        "   * V√©rifier que `http://localhost:11434` r√©pond (port par d√©faut d‚ÄôOllama)\n",
        "\n",
        "---\n",
        "\n",
        "### **B. Structure des fichiers du projet**\n",
        "\n",
        "```\n",
        "/websearch-briefing-bot\n",
        "‚îú‚îÄ‚îÄ server.py\n",
        "‚îú‚îÄ‚îÄ client.py\n",
        "‚îú‚îÄ‚îÄ .env\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ postman_collection.json (ou des exemples cURL)\n",
        "‚îî‚îÄ‚îÄ samples/\n",
        "      ‚îî‚îÄ‚îÄ brief_YYYY-MM-DD.md\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **C. Impl√©mentation du serveur HTTP (FastAPI)**\n",
        "\n",
        "#### 1. D√©marrage FastAPI avec Bearer Auth\n",
        "\n",
        "* Utiliser un `Depends` pour v√©rifier le header Authorization sur toutes les routes.\n",
        "\n",
        "#### 2. Endpoints √† impl√©menter\n",
        "\n",
        "* `GET  /tools`\n",
        "  ‚Üí Retourne la liste des outils et leur sch√©ma d‚Äôentr√©e attendu (en JSON)\n",
        "\n",
        "* `POST /tools/search_web`\n",
        "\n",
        "  * Entr√©e : `{ \"query\": string, \"k\": int }`\n",
        "  * Sortie : `[ { \"title\", \"url\", \"snippet\", \"source\" } ]`\n",
        "  * Appelle l‚ÄôAPI Google CSE ou Tavily\n",
        "\n",
        "* `POST /tools/fetch_readable`\n",
        "\n",
        "  * Entr√©e : `{ \"url\": string }`\n",
        "  * Sortie : `{ \"url\", \"title\", \"text\" }`\n",
        "  * Utilise `requests` + `readability-lxml`\n",
        "\n",
        "* `POST /tools/summarize_with_citations`\n",
        "\n",
        "  * Entr√©e : `{ \"topic\": string, \"docs\": [ { \"title\", \"url\", \"text\" } ] }`\n",
        "  * Sortie : `{ bullets: [str], sources: [{i,title,url}] }`\n",
        "  * Appelle Ollama via HTTP, prompt√© pour faire 5 bullets ‚â§ 200 caract√®res, citations \\[1]...\\[N]\n",
        "\n",
        "* `POST /tools/save_markdown`\n",
        "\n",
        "  * Entr√©e : `{ \"filename\": str, \"content\": str }`\n",
        "  * Sauvegarde sur disque (g√©rer les chemins Windows)\n",
        "  * Retour : `{ \"path\": str }`\n",
        "\n",
        "#### 3. Gestion des erreurs / timeout\n",
        "\n",
        "* Timeout pour les appels HTTP (search, LLM)\n",
        "* Retour d‚Äôerreur JSON explicite en cas d‚Äôexception\n",
        "* Validation stricte des entr√©es (Pydantic)\n",
        "\n",
        "---\n",
        "\n",
        "### **D. Impl√©mentation du client CLI**\n",
        "\n",
        "* Argument : le sujet du briefing (`your topic`)\n",
        "* Encha√Ænement :\n",
        "\n",
        "  1. Appelle `/tools/search_web` (r√©cup√®re k r√©sultats)\n",
        "  2. Pour les 3 premiers domaines : `/tools/fetch_readable`\n",
        "  3. Appelle `/tools/summarize_with_citations` (avec topic + docs lus)\n",
        "  4. Appelle `/tools/save_markdown` (markdown avec bullets + sources)\n",
        "  5. Affiche le chemin du markdown g√©n√©r√©\n",
        "\n",
        "---\n",
        "\n",
        "### **E. README + Exemples cURL/Postman + Sample Output**\n",
        "\n",
        "* README avec pr√©requis, setup, usage\n",
        "* Exemple de run complet du CLI\n",
        "* Exemples cURL pour chaque endpoint\n",
        "* Fichier sample `brief_YYYY-MM-DD.md` valide\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Mod√®le de fichiers essentiels (pseudo-code de d√©marrage)\n",
        "\n",
        "### **.env**\n",
        "\n",
        "```\n",
        "MCP_HTTP_TOKEN=your_secret_token\n",
        "GOOGLE_CSE_API_KEY=xxx\n",
        "GOOGLE_CSE_CX=yyy\n",
        "```\n",
        "\n",
        "### **server.py (extrait simplifi√© FastAPI)**\n",
        "\n",
        "```python\n",
        "from fastapi import FastAPI, HTTPException, Request, Depends\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict\n",
        "import os, requests\n",
        "\n",
        "app = FastAPI()\n",
        "TOKEN = os.getenv(\"MCP_HTTP_TOKEN\")\n",
        "\n",
        "def verify_token(request: Request):\n",
        "    auth = request.headers.get(\"authorization\")\n",
        "    if not auth or not auth.startswith(\"Bearer \") or auth.split(\" \")[1] != TOKEN:\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "\n",
        "@app.get(\"/tools\", dependencies=[Depends(verify_token)])\n",
        "def list_tools():\n",
        "    return {...} # Liste outils + schemas\n",
        "\n",
        "class SearchIn(BaseModel):\n",
        "    query: str\n",
        "    k: int\n",
        "\n",
        "@app.post(\"/tools/search_web\", dependencies=[Depends(verify_token)])\n",
        "def search_web(input: SearchIn):\n",
        "    # Appel Google CSE ou Tavily\n",
        "    return ...\n",
        "\n",
        "# Idem pour les autres endpoints...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "```\n",
        "\n",
        "### **client.py (extrait CLI Typer)**\n",
        "\n",
        "```python\n",
        "import typer, requests, os\n",
        "\n",
        "API = \"http://localhost:8000/tools\"\n",
        "TOKEN = os.getenv(\"MCP_HTTP_TOKEN\")\n",
        "\n",
        "def call(endpoint, payload):\n",
        "    r = requests.post(f\"{API}/{endpoint}\", json=payload, headers={\"Authorization\": f\"Bearer {TOKEN}\"})\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def brief(topic: str):\n",
        "    res = call(\"search_web\", {\"query\": topic, \"k\": 5})\n",
        "    docs = [call(\"fetch_readable\", {\"url\": r[\"url\"]}) for r in res[:3]]\n",
        "    summary = call(\"summarize_with_citations\", {\"topic\": topic, \"docs\": docs})\n",
        "    markdown = ... # formater le markdown avec bullets + sources\n",
        "    path = call(\"save_markdown\", {\"filename\": f\"brief_{date}.md\", \"content\": markdown})[\"path\"]\n",
        "    print(path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    typer.run(brief)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conseils & Pi√®ges √† √©viter\n",
        "\n",
        "* **API Key** : ne jamais commit dans le code, toujours via .env\n",
        "* **Timeout** sur tous les appels externes, sinon blocage potentiel\n",
        "* **Gestion Unicode** et encodage fichiers sous Windows\n",
        "* **V√©rification API LLM** : prompt sp√©cial pour citations et format pr√©cis, sinon risque de d√©calage\n",
        "* **Compatibilit√© Windows** : attention aux chemins relatifs, privil√©gier `os.path.join`\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Livrables\n",
        "\n",
        "* Code source comment√©, lisible, testable sous Win10/Python 3.11/VSCode\n",
        "* Un README complet et actionnable\n",
        "* Une collection Postman ou script cURL minimal pour chaque endpoint\n",
        "* Un fichier markdown de r√©sultat r√©el (brief\\_YYYY-MM-DD.md)\n",
        "\n",
        "---\n",
        "\n",
        "**Cette approche couvre 100% du p√©rim√®tre, respecte les contraintes, et assure un setup simple et reproductible sous Windows 10, Python 3.11 et VSCode.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "718d5047",
      "metadata": {
        "id": "718d5047"
      },
      "source": [
        "**Plan de d√©veloppement √©tape par √©tape** pour r√©aliser ce projet de mani√®re **compl√®te, compatible et directement ex√©cutable** sous VSCode, Windows 10 et Python 3.11.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Initialisation du projet\n",
        "\n",
        "### A. Cr√©e le dossier et le virtualenv\n",
        "\n",
        "```sh\n",
        "mkdir websearch_briefing_bot\n",
        "cd websearch_briefing_bot\n",
        "python -m venv .venv\n",
        ".venv\\Scripts\\activate\n",
        "```\n",
        "\n",
        "### B. Installe les d√©pendances n√©cessaires\n",
        "\n",
        "```sh\n",
        "pip install fastapi uvicorn requests python-dotenv readability-lxml typer\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Pr√©pare le fichier `.env`\n",
        "\n",
        "Exemple¬†:\n",
        "\n",
        "```\n",
        "MCP_HTTP_TOKEN=secret123\n",
        "GOOGLE_CSE_API_KEY=TA_CLE_API\n",
        "GOOGLE_CSE_CX=TA_CX\n",
        "```\n",
        "\n",
        "*(Remplace par tes vraies valeurs Google, ou adapte pour Tavily si tu pr√©f√®res cette API)*\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Impl√©mentation du serveur HTTP (FastAPI)\n",
        "\n",
        "### Cr√©e un fichier `server.py`\n",
        "\n",
        "#### Sch√©ma de d√©marrage minimal (structure)\n",
        "\n",
        "```python\n",
        "import os\n",
        "from fastapi import FastAPI, Request, HTTPException, Depends\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "\n",
        "load_dotenv()\n",
        "TOKEN = os.getenv(\"MCP_HTTP_TOKEN\")\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_CSE_API_KEY\")\n",
        "GOOGLE_CSE_CX = os.getenv(\"GOOGLE_CSE_CX\")\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "def verify_token(request: Request):\n",
        "    auth = request.headers.get(\"authorization\")\n",
        "    if not auth or not auth.startswith(\"Bearer \") or auth.split(\" \")[1] != TOKEN:\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "\n",
        "@app.get(\"/tools\", dependencies=[Depends(verify_token)])\n",
        "def list_tools():\n",
        "    return {\n",
        "        \"tools\": [\n",
        "            \"search_web\", \"fetch_readable\", \"summarize_with_citations\", \"save_markdown\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "class SearchIn(BaseModel):\n",
        "    query: str\n",
        "    k: int\n",
        "\n",
        "@app.post(\"/tools/search_web\", dependencies=[Depends(verify_token)])\n",
        "def search_web(input: SearchIn):\n",
        "    url = (\n",
        "        \"https://www.googleapis.com/customsearch/v1\"\n",
        "        f\"?key={GOOGLE_API_KEY}&cx={GOOGLE_CSE_CX}&q={input.query}\"\n",
        "    )\n",
        "    resp = requests.get(url, timeout=10)\n",
        "    items = resp.json().get(\"items\", [])\n",
        "    results = []\n",
        "    for it in items[:input.k]:\n",
        "        results.append({\n",
        "            \"title\": it.get(\"title\"),\n",
        "            \"url\": it.get(\"link\"),\n",
        "            \"snippet\": it.get(\"snippet\"),\n",
        "            \"source\": \"google\"\n",
        "        })\n",
        "    return results\n",
        "\n",
        "class FetchIn(BaseModel):\n",
        "    url: str\n",
        "\n",
        "@app.post(\"/tools/fetch_readable\", dependencies=[Depends(verify_token)])\n",
        "def fetch_readable(input: FetchIn):\n",
        "    from readability import Document\n",
        "    r = requests.get(input.url, timeout=10)\n",
        "    doc = Document(r.text)\n",
        "    return {\n",
        "        \"url\": input.url,\n",
        "        \"title\": doc.title(),\n",
        "        \"text\": doc.summary()\n",
        "    }\n",
        "\n",
        "class SummarizeIn(BaseModel):\n",
        "    topic: str\n",
        "    docs: List[Dict]\n",
        "\n",
        "@app.post(\"/tools/summarize_with_citations\", dependencies=[Depends(verify_token)])\n",
        "def summarize_with_citations(input: SummarizeIn):\n",
        "    # Prompt et appel Ollama\n",
        "    ollama_url = \"http://localhost:11434/api/chat\"\n",
        "    prompt = (\n",
        "        f\"R√©sume en 5 bullets points (<= 200 caract√®res chacun) avec citations [1]..[N].\\n\"\n",
        "        f\"Topic: {input.topic}\\n\"\n",
        "        \"Documents:\\n\" +\n",
        "        \"\\n\".join(f\"[{i+1}] {doc['title']} : {doc['text'][:1000]}...\" for i, doc in enumerate(input.docs))\n",
        "    )\n",
        "    payload = {\"model\": \"llama3\", \"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
        "    res = requests.post(ollama_url, json=payload, timeout=30)\n",
        "    # √Ä affiner selon le format Ollama\n",
        "    output = res.json()[\"message\"][\"content\"]\n",
        "    # Extraction simple √† compl√©ter\n",
        "    bullets = output.strip().split(\"\\n\")[:5]\n",
        "    sources = [\n",
        "        {\"i\": i+1, \"title\": doc[\"title\"], \"url\": doc[\"url\"]} for i, doc in enumerate(input.docs)\n",
        "    ]\n",
        "    return {\"bullets\": bullets, \"sources\": sources}\n",
        "\n",
        "class SaveIn(BaseModel):\n",
        "    filename: str\n",
        "    content: str\n",
        "\n",
        "@app.post(\"/tools/save_markdown\", dependencies=[Depends(verify_token)])\n",
        "def save_markdown(input: SaveIn):\n",
        "    folder = \"samples\"\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    path = os.path.join(folder, input.filename)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(input.content)\n",
        "    return {\"path\": os.path.abspath(path)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
        "```\n",
        "\n",
        "**NB**: Pour le r√©sum√©, adapte le parsing selon la sortie r√©elle d‚ÄôOllama.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Impl√©mentation du client CLI\n",
        "\n",
        "### Cr√©e un fichier `client.py`\n",
        "\n",
        "```python\n",
        "import os\n",
        "import requests\n",
        "import typer\n",
        "from datetime import date\n",
        "\n",
        "API_URL = \"http://127.0.0.1:8000/tools\"\n",
        "TOKEN = os.getenv(\"MCP_HTTP_TOKEN\")\n",
        "HEADERS = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
        "\n",
        "def post(endpoint, data):\n",
        "    url = f\"{API_URL}/{endpoint}\"\n",
        "    r = requests.post(url, json=data, headers=HEADERS, timeout=20)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def main(topic: str):\n",
        "    results = post(\"search_web\", {\"query\": topic, \"k\": 5})\n",
        "    docs = []\n",
        "    for r in results[:3]:\n",
        "        doc = post(\"fetch_readable\", {\"url\": r[\"url\"]})\n",
        "        docs.append(doc)\n",
        "    summary = post(\"summarize_with_citations\", {\"topic\": topic, \"docs\": docs})\n",
        "    bullets_md = \"\\n\".join(f\"- {b}\" for b in summary[\"bullets\"])\n",
        "    sources_md = \"\\n\".join(\n",
        "        f\"[{s['i']}] [{s['title']}]({s['url']})\" for s in summary[\"sources\"]\n",
        "    )\n",
        "    content = f\"# {topic}\\n\\n{bullets_md}\\n\\n## Sources\\n{sources_md}\\n\"\n",
        "    filename = f\"brief_{date.today()}.md\"\n",
        "    result = post(\"save_markdown\", {\"filename\": filename, \"content\": content})\n",
        "    print(\"Brief enregistr√© :\", result[\"path\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    typer.run(main)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Lancement du serveur\n",
        "\n",
        "```sh\n",
        "python server.py\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Lancement du client\n",
        "\n",
        "```sh\n",
        "python client.py \"Ton sujet √† r√©sumer\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Fournir le README, les exemples cURL, et un exemple markdown\n",
        "\n",
        "* D√©cris pr√©cis√©ment l‚Äôinstallation (d√©pendances, configuration, cl√© API, lancement de Ollama, etc).\n",
        "* Exemple de chaque endpoint en cURL ou via Postman.\n",
        "* Exporte un markdown `brief_YYYY-MM-DD.md` g√©n√©r√©.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. V√©rifications de compatibilit√©\n",
        "\n",
        "* **Test sur VSCode sous Windows 10, Python 3.11**.\n",
        "* Les chemins doivent fonctionner sur Windows.\n",
        "* Les d√©pendances sont l√©g√®res, installation rapide.\n",
        "\n",
        "---\n",
        "\n",
        "**Tout le plan est valid√©, compatible, reproductible. Si tu veux le code complet de chaque partie, dis pr√©cis√©ment le fichier ou la section √† g√©n√©rer.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39266c66",
      "metadata": {
        "id": "39266c66"
      },
      "source": [
        "**README complet**, adapt√© pour ce projet, valid√© pour VSCode, Windows 10, Python 3.11, configuration locale, usage rapide et reproductible.\n",
        "\n",
        "---\n",
        "\n",
        "# Web Search Briefing Bot\n",
        "\n",
        "## Objectif\n",
        "\n",
        "Ce projet fournit :\n",
        "\n",
        "* un **serveur HTTP** exposant une API JSON pour recherche web, extraction d‚Äôarticles, r√©sum√© LLM, et sauvegarde markdown,\n",
        "* un **client CLI** qui orchestre tout le flow (recherche, extraction, r√©sum√©, sauvegarde) et produit un rapport markdown structur√© avec sources,\n",
        "* un exemple reproductible, cl√© en main, compatible Windows 10, Python 3.11 et VSCode.\n",
        "\n",
        "---\n",
        "\n",
        "## Pr√©requis\n",
        "\n",
        "* Windows 10 (compatible aussi Linux/Mac)\n",
        "* Python 3.11 install√©\n",
        "* [Ollama](https://ollama.com) (LLM local) install√© et d√©marr√© (`ollama run llama3`)\n",
        "* Compte et cl√©s API d‚Äôun moteur de recherche gratuit¬†:\n",
        "\n",
        "  * [Google Programmable Search Engine (CSE)](https://developers.google.com/custom-search/v1/overview)\n",
        "    ou [Tavily](https://docs.tavily.com/)\n",
        "\n",
        "---\n",
        "\n",
        "## Installation\n",
        "\n",
        "### 1. Clone le projet\n",
        "\n",
        "```sh\n",
        "git clone <url_du_repo>\n",
        "cd websearch_briefing_bot\n",
        "```\n",
        "\n",
        "### 2. Active un environnement Python\n",
        "\n",
        "```sh\n",
        "python -m venv .venv\n",
        ".venv\\Scripts\\activate\n",
        "```\n",
        "\n",
        "### 3. Installe les d√©pendances\n",
        "\n",
        "```sh\n",
        "pip install fastapi uvicorn requests python-dotenv readability-lxml typer\n",
        "```\n",
        "\n",
        "### 4. Configure `.env` avec tes cl√©s\n",
        "\n",
        "Cr√©e un fichier `.env` √† la racine¬†:\n",
        "\n",
        "```\n",
        "MCP_HTTP_TOKEN=choisis_un_token_fort\n",
        "GOOGLE_CSE_API_KEY=ta_cle_api_google\n",
        "GOOGLE_CSE_CX=ton_cx_google\n",
        "```\n",
        "\n",
        "*(ou adapte pour Tavily, cf. leur doc)*\n",
        "\n",
        "---\n",
        "\n",
        "### 5. D√©marre le mod√®le LLM local (Ollama)\n",
        "\n",
        "T√©l√©charge et installe Ollama, puis lance¬†:\n",
        "\n",
        "```sh\n",
        "ollama run llama3\n",
        "```\n",
        "\n",
        "*(Laisse tourner Ollama pendant toute l‚Äôutilisation du bot.)*\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Lance le serveur HTTP\n",
        "\n",
        "```sh\n",
        "python server.py\n",
        "```\n",
        "\n",
        "Le serveur √©coute sur [http://127.0.0.1:8000](http://127.0.0.1:8000)\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Utilisation du client CLI\n",
        "\n",
        "G√©n√®re un briefing sur un sujet¬†:\n",
        "\n",
        "```sh\n",
        "python client.py \"intelligence artificielle et m√©decine\"\n",
        "```\n",
        "\n",
        "Le rapport est g√©n√©r√© dans le dossier `samples` sous le nom `brief_YYYY-MM-DD.md`.\n",
        "\n",
        "---\n",
        "\n",
        "## Exemple de workflow complet\n",
        "\n",
        "```sh\n",
        "python client.py \"avenir de la voiture √©lectrique en Europe\"\n",
        "```\n",
        "\n",
        "Affichage¬†:\n",
        "\n",
        "```\n",
        "Brief enregistr√© : C:\\...\\websearch_briefing_bot\\samples\\brief_2025-08-18.md\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## API Endpoints\n",
        "\n",
        "**Authentification Bearer obligatoire**¬†:\n",
        "Ajouter dans les headers¬†:\n",
        "`Authorization: Bearer <MCP_HTTP_TOKEN>`\n",
        "\n",
        "### GET `/tools`\n",
        "\n",
        "Liste les outils disponibles.\n",
        "\n",
        "### POST `/tools/search_web`\n",
        "\n",
        "**Entr√©e¬†:**\n",
        "\n",
        "```json\n",
        "{ \"query\": \"mot cl√©\", \"k\": 5 }\n",
        "```\n",
        "\n",
        "**Sortie¬†:**\n",
        "Liste des r√©sultats¬†: `[ { \"title\", \"url\", \"snippet\", \"source\" } ]`\n",
        "\n",
        "### POST `/tools/fetch_readable`\n",
        "\n",
        "**Entr√©e¬†:**\n",
        "\n",
        "```json\n",
        "{ \"url\": \"https://...\" }\n",
        "```\n",
        "\n",
        "**Sortie¬†:**\n",
        "\n",
        "```json\n",
        "{ \"url\": \"...\", \"title\": \"...\", \"text\": \"...\" }\n",
        "```\n",
        "\n",
        "### POST `/tools/summarize_with_citations`\n",
        "\n",
        "**Entr√©e¬†:**\n",
        "\n",
        "```json\n",
        "{ \"topic\": \"sujet\", \"docs\": [{ \"title\": \"...\", \"url\": \"...\", \"text\": \"...\" }] }\n",
        "```\n",
        "\n",
        "**Sortie¬†:**\n",
        "\n",
        "```json\n",
        "{ \"bullets\": [\"...\", \"...\"], \"sources\": [ { \"i\": 1, \"title\": \"...\", \"url\": \"...\" } ] }\n",
        "```\n",
        "\n",
        "### POST `/tools/save_markdown`\n",
        "\n",
        "**Entr√©e¬†:**\n",
        "\n",
        "```json\n",
        "{ \"filename\": \"brief_2025-08-18.md\", \"content\": \"# markdown...\" }\n",
        "```\n",
        "\n",
        "**Sortie¬†:**\n",
        "\n",
        "```json\n",
        "{ \"path\": \"C:/.../samples/brief_2025-08-18.md\" }\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Exemples cURL\n",
        "\n",
        "```sh\n",
        "curl -H \"Authorization: Bearer ton_token\" http://127.0.0.1:8000/tools\n",
        "```\n",
        "\n",
        "```sh\n",
        "curl -H \"Authorization: Bearer ton_token\" -X POST http://127.0.0.1:8000/tools/search_web -d \"{\\\"query\\\":\\\"voiture autonome\\\",\\\"k\\\":3}\" -H \"Content-Type: application/json\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Exemple de rapport g√©n√©r√©\n",
        "\n",
        "**samples/brief\\_2025-08-18.md**¬†:\n",
        "\n",
        "```markdown\n",
        "# avenir de la voiture √©lectrique en Europe\n",
        "\n",
        "- Les ventes de voitures √©lectriques ont fortement progress√© en 2024 [1].\n",
        "- Les infrastructures de recharge restent un point faible majeur [2].\n",
        "- Plusieurs pays annoncent la fin des v√©hicules thermiques d‚Äôici 2035 [3].\n",
        "- Le co√ªt des batteries continue de baisser, favorisant l‚Äôadoption [2].\n",
        "- Les constructeurs acc√©l√®rent la transition mais restent d√©pendants de la Chine pour les mat√©riaux strat√©giques [1].\n",
        "\n",
        "## Sources\n",
        "\n",
        "[1] [March√© europ√©en de l‚Äô√©lectrique 2024](https://www.lemonde.fr/auto/)\n",
        "[2] [Le Figaro ‚Äì Bornes de recharge](https://www.lefigaro.fr/auto/)\n",
        "[3] [Euronews ‚Äì Fin du thermique](https://www.euronews.com/motoring/)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## D√©pannage\n",
        "\n",
        "* **401 Unauthorized**¬†: V√©rifie le token Bearer dans l‚Äôen-t√™te et dans `.env`\n",
        "* **403 sur search**¬†: V√©rifie tes cl√©s et CX Google (ou Tavily).\n",
        "* **Ollama non lanc√©**¬†: D√©marre bien `ollama run llama3` avant toute requ√™te de r√©sum√©.\n",
        "* **Texte vide sur certains sites**¬†: Certains sites sont peu ‚Äúparsables‚Äù automatiquement. Change d‚ÄôURL ou ajuste la valeur de `k`.\n",
        "\n",
        "---\n",
        "\n",
        "## Cr√©dits / Licence\n",
        "\n",
        "Projet inspir√© par le challenge ‚ÄúHTTP Web Search Briefing Bot‚Äù (XP MCP 2025).\n",
        "Code libre, r√©utilisable et am√©liorable pour tout projet d‚Äôautomatisation de veille avec IA locale.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}